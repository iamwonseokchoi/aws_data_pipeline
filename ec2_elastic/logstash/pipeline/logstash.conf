input {
  kafka {
    bootstrap_servers => "b-1.amorekafkacluster.0hc19c.c3.kafka.ap-northeast-2.amazonaws.com:9096"
    topics => ["es_events"]
    group_id => "logstash"
    codec => "json"
    consumer_threads => 3
    security_protocol => "SASL_SSL"
    sasl_mechanism => "SCRAM-SHA-512"
    sasl_jaas_config => 'org.apache.kafka.common.security.scram.ScramLoginModule required username="wonseokchrischoi" password="admin1234!";'
  }
}

filter {
  json {
    source => "message"
    target => "parsed"
  }

  mutate {
    add_field => {
      "longitude" => "%{[parsed][location][0]}"
      "latitude" => "%{[parsed][location][1]}"
    }
  }

  ruby {
    code => "
      location_array = event.get('[parsed][location]')
      if location_array
        region = location_array[2..-1].join(', ')
        event.set('region', region)
      end
    "
  }
}

output {
  elasticsearch {
    hosts => ["http://3.37.44.51:9200"]
    user => "elastic"
    password => "${LOGSTASH_INTERNAL_PASSWORD}"
    index => "es_events-%{+YYYY.MM.dd}"
  }
}
